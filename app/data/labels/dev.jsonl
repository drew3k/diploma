{"text": "Трифонов Вадим Дмитриевич\nЖелаемая должность: Специалист по машинному обучению (Machine Learning Engineer)\nЭлектронная почта trifffonov.vadim@mail.ru Телефон: +79153054440\nTelegram: @TriFon_V\n\nЗанятость: Стажировка\nГрафик работы: Гибкий график\nЛичная информация\nГражданство Россия\nДата рождения: 17.09.2004 (20 лет) Город проживания Москва\nОбразование\nНа данный момент являюсь студентом РТУ МИРЭА. Учебное заведение РТУ МИРЭА.\nГод окончания: 2026\nФакультет: Институт Информационных Технологий Направление подготовки: Программная инженерия\nСпециальность: Интеллектуальные системы поддержки принятия решений Форма обучения: Очная\nНавыки\nPython (TensorFlow, PyTorch, NumPy, Pandas): Базовый SQL: Базовый\nGit: Базовый\nUML, IDEF, BPMN, ARIS: Базовый\nЗнание различных архитектур нейронных сетей, принципов их работы (MLP, RNN, CNN, GNN, Transformer).\nКачества\n\nПунктуальность\nОбучаемость\nУмение работать в команде\n\n\nО себе\nНачинающий Machine Learning Engineer с теоретической базой, полученной в рамках курса в РТУ МИРЭА по специальности Интеллектуальные системы поддержки принятия решений. В рамках курсовой работы проводил экспериментальное сравнение четырёх ключевых типов сетевых архитектур на задаче многоклассовой классификации комментариев из социальных сетей с использованием датасета RuSentiment. Участник окружного хакатона от\n«Цифровой прорыв» в Приволжском федеральном округе. В составе команды SynapseSquad занял 6 место. В кейсе от ОАО «РЖД» «Диспетчерский контроль», стояла задача реализовать решение, с применением ИИ, которое позволит распознавать поезда, контролировать занятость/свободность путей и формировать отчеты для диспетчеров. Для распознавания и анализа объектов использовали модель Mask R-CNN с архитектурой ResNet-50, реализованную с помощью фреймворка Detectron2. В команде я выступил в роли Project Manager. Также мной была проделана работа с отметкой объектов на видео при помощи масок с использованием программы LabelMe. Из результатов могу выделить, что модель успешно классифицировала объекты, определяла риски появления объектов, не относящихся к поездам на путях, определяла время занятости и свободности каждого из представленных путей, а также формировался отчет в формате Excel таблицы.Активно изучаю новые технологии и стремлюсь к профессиональному росту в области машинного обучения. Ищу возможность поработать с профессионалами на реальных задачах, укрепить существующие навыки и приобрести новые.\ntrifffonov.vadim@mail.ru", "entities": [[0, 25, "PERSON"], [204, 221, "PERSON"], [262, 285, "PERSON"], [316, 339, "ADDRESS"], [387, 396, "PERSON"], [416, 425, "PERSON"], [458, 504, "PERSON"], [622, 634, "PERSON"], [737, 751, "PERSON"], [845, 881, "PERSON"], [1351, 1381, "ADDRESS"]]}
{"text": "Оганнисян Григор\nМужчина, 21 год, родился 24 мая 2004\n+7 (901) 7796914\ngrigorogannisyan.12@yandex.ru — предпочитаемый способ связи\nПроживает: Железнодорожный  (Московская область)\nГражданство: Россия, есть разрешение на работу: Россия\nНе готов к переезду, не готов к командировкам\nЖелаемая должность и зарплата\nGolang-разработчик\nСпециализации:\n—  Программист, разработчик\nЗанятость: полная занятость, стажировка\nГрафик работы: полный день, удаленная работа\nЖелательное время в пути до работы: не имеет значения\nОпыт работы — 1 год 10 месяцев\nИюль 2024 —\nнастоящее время\n1 год 4 месяца\nПроектная деятельность в сфере разработки\ngithub.com/Anabol1ks\nBackend-разработчик (частичная занятость, фриланс / pet-проекты,\nopen-source)\nРеализация проектов:\n1. LinkVault — https://github.com/Anabol1ks/LinkVault-micro\n   Спроектировал микросервисную архитектуру (gRPC + Kafka + per‑service PostgreSQL)\n   Разработал схемы БД и миграционную стратегию для независимого масштабирования\nсервисов.\n   Реализовал полный цикл JWT (access/refresh) с безопасной инвалидацией и разделением\nсекретов.\n   Вынес protobuf контракт в отдельный репозиторий; настроил генерацию и\nпереиспользование типов.\n   Реализовал асинхронный email‑pipeline (Kafka producer + consumer) и шаблонную отправку\nчерез SMTP.\n2. LiveEdit — https://github.com/Anabol1ks/LiveEdit\n   Многопользовательский редактор документов в реальном времени.\n   Функционал: совместное редактирование документов, управление пользователями,\nразграничение прав доступа.\n   Технологии: Go, gRPC, GORM, PostgreSQL, protobuf.\n3. Digital Queue System — https://github.com/Anabol1ks/digital-queue\n   Система электронной очереди для учебных заведений.\n   Функционал: автоматизация очередей, разделение ролей (студенты/преподаватели), панель\nадминистратора.\n   Технологии: Go (Gin), PostgreSQL, Redis, React, Next.js, Docker.\n4. Контесты и алгоритмические задачи\n- Описание: Решения задач с платформ CodeWars -\nhttps://github.com/Anabol1ks/GoLang/tree/main/CodeWars и LeetCode -\nРезюме обновлено 31 октября 2025 в 13:49\n\nhttps://github.com/Anabol1ks/GoLang/tree/main/LeetCode.\nФункционал: Содержит решения задач на массивы, строки, графы и хэш-таблицы.\nЯнварь 2024 —\nМай 2025\n1 год 5 месяцев\nНебольшая аутсорс-команда (неофициально)\nJunior Golang-разработчик\nРазработка backend-сервиса логирования событий: REST API на Go, тесты (testify), PostgreSQL,\nRedis, CI (GitHub Actions), логирование на zap.\nВзаимодействие с 2 бэкендерами и QA, проходили код-ревью, короткие релизные циклы.\nОбразование\nНеоконченное высшее\n2026\nМИРЭА — Российский технологический университет, Москва\nИнститут информационных технологий, Интеллектуальные системы поддержки принятия\nрешений\nНавыки\nЗнание языков\nРусский — Родной\nАнглийский — A1 — Начальный\nАрмянский — C1 — Продвинутый\nНавыки\n Git      MySQL      PostgreSQL      SQL      Linux      Docker      REST API      Golang \n GitHub      Python      Swagger      Работа с базами данных      Backend      Go \n HTTP      JavaScript      React      HTML      gRPC      Apache Kafka \n Микросервисная архитектура      Веб-разработка      API \nОпыт вождения\nПрава категории B\nДополнительная информация\nОбо мне\nУвлечён разработкой backend-систем с использованием GoLang.\nПобедил в хакатоне  \"{Идея.Код.Релиз}\" в роли бэкенд разработчика. Ссылка на сертификат:\nhttps://clck.ru/3Q5PQc\nУчаствовал в хакатоне \"Цифровой прорыв. Сезон: искусственный интеллект 2024\" в роли\nбэкенд разработчика. Ссылка на сертификат: https://clck.ru/3Q5PEy\nИзучаю архитектуры REST API, gRPC и работу с базами данных, микросервисную\nархитектуру и Kafka, умею писать чистый и поддерживаемый код.\nИмею высокий уровень ответственности, хорошо систематизирую работу, умею работать с\nбольшим объемом информации.\nОганнисян Григор  •  Резюме обновлено 31 октября 2025 в 13:49\n", "entities": [[0, 24, "PERSON"], [160, 179, "ADDRESS"], [193, 234, "ADDRESS"], [2511, 2535, "PERSON"], [2596, 2611, "PERSON"], [2691, 2704, "PERSON"], [2712, 2728, "ADDRESS"], [2747, 2766, "PERSON"], [2774, 2792, "PERSON"], [3734, 3750, "PERSON"]]}
{"text": "Резюме №6: Козлов Алексей Данилович\n\nМеня зовут Козлов Алексей Данилович. Рассматриваю позицию Python-разработчика с уклоном в обработку документов и защиту ПДн.\nСвязаться можно по телефону +7-968-277-60-49 или по электронной почте aleksey.kozlov@bk.ru.\nОпыт: участвовал в разработке веб-сервисов, API и инструментов для работы с PDF и DOCX.\nНу потому что так нужно вот — умею объяснять сложные вещи простым языком и люблю аккуратные регулярки. Проживаю по адресу город Краснодар, наб. Кошевого, д. 15 к. 2\nРазрабатывал конвейеры на FastAPI, PyMuPDF и python-docx; внедрял Detectors/NER и систему маскирования.\nВ рамках тестового задания могу предоставить реквизиты: карта 3829-0997-5910-5756 (только для демонстрации).\nОбразование: бакалавриат, информатика и вычислительная техника; английский — B1.\nХобби: алгоритмы, автоматизация рутин, осмысленная документация.", "entities": [[11, 35, "PERSON"], [48, 72, "PERSON"], [339, 344, "PERSON"], [464, 484, "ADDRESS"]]}
{"text": "АННОТАЦИЯ\nДанная работа посвящена созданию нейроинтерфейса, обеспечивающего прогнозирование движений рук по сигналам головного мозга и преобразование этих данных в управляющие команды для ручного протеза с применением методов машинного обучения. \nРазработанное программное обеспечение является посредником между шлемом для электроэнцефалографии и протезом, которое обрабатывает мозговую активность для предсказания движения рук и формирования управляющих команд.\nВ исследовательском разделе произведена работа по ознакомлению с существующими подходами к сбору мозговой активности, а также собраны сторонние решения, использующие мозговую активность для протезирования. Собранная информация была проанализирована, после чего были выявлены технические требования.\nВ аналитическом разделе обоснован выбор языка программирования и метод решения поставленной задачи, также с помощью UML и SADT отображена архитектура системы и ее функциональность.\nВ техническом разделе предоставлено тестирование системы, расчет надежности и руководство по использованию.\nКлючевые слова: машинное обучение, нейронные сети, нейрокомпьютерный интерфейс, связь человек-машина, нейропротез, обработка сигналов ЭЭГ. \nРабота содержит 60 страниц, 13 рисунков, 10 таблиц, 2 приложения.\n\n\n\n\n\nСПИСОК ИСПОЛЬЗОВАННЫХ СОКРАЩЕНИЙ И ТЕРМИНОВ\nЭЭГ — электроэнцефалография;\nМРТ — магнитно-резонансная томография;\nЭМГ — электромиография;\nПО — программное обеспечение;\nIDE — Integrated Development Environment (среда интегрированной разработки);\nCART — Classification and Regression Tree (дерево классификации и регрессии);\nGOSDT — Generalized Optimal Sparse Decision Tree (обобщенное оптимальное разреженное дерево решений);\nCNN — Convolutional Neural Network (свёрточная нейронная сеть);\nLSTM — Long Short-Term Memory (долгая краткосрочная память).\nВВЕДЕНИЕ\nВ настоящее время использование нейронных сетей значительно упрощают привычные задачи и открывает новые возможности в самых разных областях. В медицине такое внедрение играет значительную роль, так как способствует продлению срока жизни человека.\nЛюди, столкнувшиеся с ампутацией, вынуждены приобретать себе дорогостоящие протезы и заново учиться жить. Наиболее распространенные протезы работают за счет мышечной памяти, которая присутствует в конечности. Однако, данные виды протезов обязывают людей обучаться новому виду управления, что может занять продолжительное время. Кроме того, они являются непригодными для людей, потерявших значительную часть конечности, что подчеркивает актуальность разработки протезов с иным принципом работы. Решить предъявленную проблему способно управление за счет сигналов мозга. Растущая доступность качественного оборудования для считывания мозговой активности также усиливает актуальность разработки. \nЭлектроэнцефалограммы (ЭЭГ) активно используются для диагностики различных расстройств на ранних этапах. По особым паттернам активности мозга, то есть по различным сочетаниям некоторых ритмов может говорить о смещении внимания, изменении положения тела, а в частности и изменении положения рук.\nПрогнозирование движений человека на основе сигналов мозга является наиболее изучаемой задачей в протезировании конечностей, что также называется нейропротезированием. Для управления ручным протезом необходима быстрая обработка ЭЭГ сигналов, чтобы выявить паттерны, отвечающие за движение рук. Нейросети предоставляют возможность за кратчайшее время определять специфические паттерны, отвечающие за движение рук. Новизна данной разработки обусловлена применением современных методов машинного обучения, а также использованием отечественных технологий.\nОбъектом исследования является связь человек-машина, позволяющая взаимодействовать протезу с мозгом, а предметом — рассмотрение машинного обучения в качестве подхода к обработке ЭЭГ-сигналов. Создание данных протезов подойдет людям вне зависимости от степени повреждения конечности и не вызовет затруднений с обучением. Подобный интерфейс позволяет в реальном времени обрабатывать сигналы мозга с помощью нейронной сети и подавать команды на протез посредством управляющего устройства.\nРеализация предполагает обучение нейронной сети на большом количестве данных, в которым содержатся записи ЭЭГ различных людей, двигающих правой и левой рукой. Для создания нейроинтерфейса необходимо определить совместимость портативного шлема ЭЭГ с управляющим устройством и разработать соответствующее программное обеспечение.\nДля реализации нейрокомпьютерного интерфейса была выбрана каскадная модель жизненного цикла. Разработка будет вестись согласно ГОСТ Р ИСО/МЭК 12207-2010 (Процессы жизненного цикла программных средств) [1]. \nДля определения принципов оценки процессов жизненного цикла программного обеспечения и возможностей используют отечественный стандарт ГОСТ Р ИСО/МЭК 15504-5-2016 «Информационные технологии. Оценка процессов. Образец модели оценки жизненного цикла программного обеспечения» [2].\nВ приложении А представлен графический материал (презентация) выпускной квалификационной работы.\nВ процессе написания выпускной квалификационной работы руководствовался следующими нормативными актами:\n1.\t«О защите населения и территории от чрезвычайных ситуаций природного и техногенного характера» от 21.12.1994 № 68-ФЗх [3].\n2.\t«Об основах охраны здоровья граждан в Российской Федерации» от 21.11.2011 № 323-ФЗ [4].\n3.\t«О гражданской обороне» от 12.02.1998 № 28-ФЗ [5].\n4. Приказ Минздравсоцразвития РФ от 04.05.2012 № 477н «Об утверждении перечня состояний, при которых оказывается первая помощь, и перечня мероприятий по оказанию первой помощи» [6].\n5.\tТрудовой кодекс Российской Федерации от 30.12.2001 № 197-ФЗ (ред. 07.04.2025) [7].\n6.\tСанПин — 2.2.2/542-96 «Гигиенические требования к видеодисплейным терминалам, персональным электронно-вычислительным машинам и организации работы» [8].\n\n\nЛИТЕРАТУРНЫЙ ОБЗОР\nВ процессе изучения предметной области нейроинтерфейсов и их применения в современных системах взаимодействия с компьютерными технологиями были изучены несколько ключевых литературных источников.\nИсследование нейроинтерфейсов с неинвазивным подходом: в статье «A Survey of Brain Computer Interface Using Non Invasive Methods» рассматриваются различные неинвазивные методы создания нейроинтерфейсов [9]. Автор детально анализирует технологии, такие как магнитно-резонансная томография (МРТ), инфракрасная спектроскопия, электроэнцефалографическое (ЭЭГ) считывание и их применение в медицине. В статье также упоминается о значении портативного способа считывания мозговых сигналов в нейроинтерфейсах.\nПоследние достижения в области применения нейроинтерфейсов на основе ЭЭГ: в статье «Recent advances in EEG based BCI applications» рассматривается использование электроэнцефалограммы (ЭЭГ) в нейроинтерфейсах [10]. Авторы описывают различные алгоритмы обработки и анализ сигналов ЭЭГ, включая использование моделей глубокого обучения для повышения производительности. В работе рассматриваются различные модели, созданные за последние пять лет, для выявления их плюсов и минусов.\nВсесторонний обзор применения трансформеров для задач глубокого обучения: в статье «A Comprehensive Survey on Applications of Transformers for Deep Learning» рассматривается архитектура трансформеров, которая произвела революцию в обработке данных [11]. Авторы рассматривают различные модели на основе данной архитектуры и их области применения, описывают существующий потенциал и будущие возможности. Благодаря своей высокой производительности трансформеры нашли широкое применение в нейросетях, включая те, что используются для обработки нейроинтерфейсов.\nЭти источники предоставляют информацию о текущих направлениях в области нейроинтерфейсов, включая применение электродов для считывания мозговых сигналов, использование продвинутых алгоритмов обработки данных и их интеграцию с машинным обучением, что способствует пониманию и дальнейшему развитию этих технологий.\n\nИССЛЕДОВАТЕЛЬСКИЙ РАЗДЕЛ\nДанный раздел представляет собой ознакомление с существующими подходами к созданию нейроинтерфейса человек-машина, анализ этих решений, выявление их достоинств и недостатков. Также в разделе проведен анализ предметной области, определены основные цели и задачи, составлено техническое задание.\nОбобщенная характеристика предметной области\nСоздание нейроинтерфейса предполагает получение сведений человеческой активности в реальном времени и последовательной обработки этих сведений посредством компьютера. Существуют два метода получения данных — инвазивный и неинвазивный.\nИнвазивный метод\nСреди инвазивных способов получения информации, выделяются электродные массивы и стереоэлектроэнцефалография. Первый способ основывается на вживлении в мозг массива электродов, которые одновременно регистрируют сигналы от большого количества электродов. Второй способ подразумевает внедрение нескольких электродов в различные области мозга. Эти способы имеют слишком большое количество рисков, из-за возможности повреждения мозговой ткани при внедрении. Инвазивный метод на данное время является менее изученным, внушающим недоверие, однако имеет больше перспектив.\nНеинвазивный метод\nСамым популярным способом неинвазивного считывания мозговой активности является электроэнцефалография. Каждый электрод, подсоединенный к голове, относится к определенной зоне мозга. Понять, к какой зоне относится сигнал можно по его первой букве. Так, сигналы, начинающиеся с буквы F, относятся к лобной доле (Frontal), с буквы C к центральной доле (Central), с буквы P к теменной доле (Parietal), с буквы O к затылочной доле (Occipital), с буквы T к височной доле (Temporal), а буква А отвечает за уши (Auricle). Расположение сигналов представлено на Рисунке 1.1.\n\nРисунок 1.1 — Расположение сигналов\n Неинвазивные методы не несут в себе рисков для человеческой жизни, но могут быть менее точными, содержать много шумовых данных.\nОбласть применения\nОдной из наиболее популярных областей применения нейроинтерфейсов является протезирование, так как последующее развитие технологий способно полностью заменить функционал естественных конечностей. При использовании ЭЭГ сигналов в протезировании, важно четко понимать, какие конкретно сигналы подлежат анализу. Например, при движении правой руки наиболее активным считается левое полушарие, а именно сигналы — C3, P3, F3. При движении левой руки активно правое полушарие, а именно — C4, P4 и F4 [12].\nОбзор и анализ существующих решений в области нейроинтерфейсов функциональных протезов\nПродукт от компании «Neuralink» основывается на инвазивном способе считывания мозговой активности. Созданный ими чип «N1» вживляется в мозг, считывая нейронную активность через 1024 электрода. Несмотря на большое количество электродов, чип не имеет полной информации над мозговой активностью, только лишь над малой ее частью. Разработка находится на начальной стадии, поэтому методы обработки сигналов, а также используемые методы машинного обучения пока неизвестны. Также, компания сталкивается с проблемами над тестированием: крошечные нити импланта могут способствовать отмиранию мозговой ткани. Данную проблему решить непросто из-за естественной подвижности мозга внутри черепа, а также из-за рисков, возможных при деформации устройства самого чипа [13]. \nДля чипа предусмотрен интерфейс, с помощью которого люди могут играть в игры. По словам компании, чип будет позволять управлять протезами, однако исследования в этой области еще не были опубликованы.\nКомпания «OpenBCI» предоставляет возможность приобретения различных устройств для считывания сигналов ЭЭГ, ЭМГ и так далее. Для купленного оборудования существует специальная библиотека, написанная на языке Python, которую может использовать любой желающий для анализа данных с биосенсоров. Помимо этого, существует графический интерфейс для визуализации данных с устройств и специально разработанный драйвер. Все разработки являются open-source, что основывается на политике платформы. Там также можно найти пользовательские разработки, написанные для оборудования компании. Одной из таких разработок является «S.A.P.I.E.N.S», которая позволяет управлять ручным протезом, на основе предсказания нейронной сети [14]. Поскольку данное программное обеспечение не реализовано самой компанией, могут возникнуть сложности при его использовании. Еще одной проблемой является недоступность официального сайта OpenBCI на территории России, из чего вытекают возможные проблемы с приобретением их оборудования.\nКомпания «Emotiv» также предоставляет возможность приобретения различных шлемов, для получения ЭЭГ сигналов. На официальном сайте присутствует программное обеспечение компании, которое позволяет считывать сигналы в реальном времени, а также обрабатывать их. В основном, на сайте представлено использование этих программ для тренировки мозга через особые игры [15]. С помощью некоторой настройки есть возможность использовать их шлемы для управления протезом, но с этим справится не каждый. Для использования их программного обеспечения требуется ежемесячная подписка, что может быть весьма затратно. Как и у предыдущей компании, для шлемов Emotiv существуют пользовательские разработки, которые предназначены для управления ручным протезом. Однако, в отличие от OpenBCI, сами разработки не выложены в общий доступ, по ним есть лишь статьи.\nРазработка, опубликованная в международном журнале новейших технологий и инженерии в январе 2020 года, представляет собой нейроинтерфейс, обрабатывающий сигналы ЭЭГ с помощью нейросети [16]. К сожалению, по данной разработке существует только подробная статья, само программное обеспечение недоступно. Тем не менее, использование нейронной сети делает данную разработку наиболее современной. Для считывания сигналов использовался шлем «Neurosky mobile 2», который хоть и является портативным и недорогим устройством, имеет всего лишь один электрод. Обучение происходило на наборе данных, собранных самостоятельно с помощью данного шлема. Собранные данные не являются достаточно качественными из-за считывания всего лишь одного канала. Решение представляет собой нейронную сеть LSTM с точностью обучения 62%.\nОсновываясь на существующих решениях, можно сделать вывод, что в данной области нет достаточно популярного решение, которое активно используется и является общедоступным. Более того, каждое из приведенных решений использует зарубежные технологии, которые имеют высокую стоимость, сложность в приобретении и могут быть непросты в использовании. В большинстве существующих разработок отсутствует прозрачность в решении, что не представляет возможность улучшения сторонними пользователями. \nНовизной настоящей работы является создание общедоступного программного обеспечения, содержащее в себе наиболее современные методы для классификации сигналов и их предобработки. Программа будет взаимодействовать с отечественным шлемом, который способен считывать наиболее релевантные сигналы для прогнозирования движения рук, а также предоставлять возможность дообучения для классификации большего количества движений и возможность улучшения архитектуры.\nИспользование достаточного набора данных для обучения, в котором присутствует 6 каналов, а также возможность взаимодействия с отечественным портативным шлемом, который также способен считывать 6 каналов должно способствовать более качественной классификации\nПостановка задачи\nЦелью разработки является создание нейроинтерфейса для управления протезом, который подразумевает взаимодействие современного отечественного шлема ЭЭГ, одноплатного компьютера и сервоприводов, находящихся на протезе. \nВ отличие от существующих разработок, предлагаемое решение предполагает использование отечественного шлема, который способен считывать большее количество сигналов, и современных методов машинного обучения, а также публикацию исходного кода в общий доступ. \nДля достижения поставленной цели, необходимо провести анализ существующих решений, подготовить техническое задание, найти набор данных для обучения нейросети, провести его предобработку, спроектировать и разработать интерфейс, обучить модель нейронной сети, протестировать работоспособность и рассчитать надежность, сформировать подробную пользовательскую документацию.\nТехническое задание на разработку\nВ данном подразделе представлено техническое задание на разработку нейроинтерфейса для функционального протеза. Техническое задание разработано на основе ГОСТ 34.602-89 [17].\nНазначение и цели разработки системы\nПолное наименование темы: «Нейрокомпьютерный, человеко-машинный интерфейс функциональных протезов».\nЦель работы: разработать интерфейс человек-машина, который обрабатывает сигналы мозга с помощью алгоритма машинного обучения и формирует команды для протеза.\nЗадачи работы:\nПровести анализ существующих решений.\n Разработать техническое задание.\n Выбрать язык программирования и среду разработки.\n Сформировать набор данных ЭЭГ сигналов, состоящий из 6 каналов, а также имеющий метки, отвечающие за поднятие правой и левой рук.\nПровести предобработку данных.\n Спроектировать и разработать нейроинтерфейс.\nОбучить модель нейронной сети.\n Провести тестирование.\n Провести расчет надежности.\n Создать пользовательскую документацию\nНазначение: предоставление возможности управление ручным протезом с помощью сигналов мозга.\nФункциональные требования\nПрограмма должна считывать сигналы с шлема в реальном времени.\nПрограмма должна производить предсказания на основе полученных сигналов.\nПрограмма должна формировать управляющие команды на основе предсказаний.\nНефункциональные требования\nВремя обработки сигналов не должно занимать более трех секунд.\nТочность предсказания должна быть выше 60%.\nПрограмма должна запускаться автоматически при включении одноплатного компьютера.\nТребования к аппаратно-программной платформе\nПриведенные требования к аппаратной и программной части должны гарантировать корректную работу программного обеспечения.\nАппаратная часть\nДля запуска программного обеспечения и его корректной работы с портативным шлемом рекомендуется использовать позиции со следующими минимальными техническими характеристиками:\nОперативная память (ОЗУ) — 8 Гб.\nОбъем дискового пространства (HDD/SSD) — 256 Гб.\nПроцессор — 4 ядра.\nBluetooth — 5.0.\nЭЭГ шлем — NeoRec cap 16.\nСервопривод — SG90.\nПрограммная часть\nСредой выполнения должна поддерживаться версия интерпретатора Python 3.9 и выше.\nОперационная система — Windows 10 и выше.\nСтандартные пакеты.\nБиблиотеки: NumPy, Matplotlib, PyLSL, PyTorch, Scipy, pigpio, pandas, sklearn, seaborn.\nПорядок контроля\nРазработка должна сопровождаться регулярной проверкой работоспособности, любые обнаруженные неполадки необходимо зафиксировать, а после чего устранить.\nТребования к программной документации\nСостав программной документации должен включать:\nВведение.\nТехническое задание.\nОписание программы\nПояснительная записка.\nИсходный код программы.\nОписание и применение.\nСтадии разработки\nРазработка должна быть проведена в четыре стадии:\nПостановка задачи и анализ предметной области.\nРазработка технического задания.\nПроектирование нейроинтерфейса.\nОценка точности распознавания движений.\nЭтапы разработки\nСтадия разработки технического задания подразумевает его составление технического задания и его утверждения.\nСтадия проектирования включает себя проектирование нейросети, сбор данных для ее обучения, обучение нейросети, обеспечение взаимодействия с шлемом и с протезом, а также разработку программной документации.\nОценка точности распознаваний движений определяется путем использования различных метрик, а также сравнение этих метрик с метриками других решений.\nВывод по исследовательскому разделу\nВ данном разделе был проведен анализ предметной области, а также изучены существующие решения в данной области, на основе чего получилось выявить необходимые требования к нейроинтерфейсу, помогающие ему стать наиболее востребованным и качественным.\n\nАНАЛИТИЧЕСКИЙ РАЗДЕЛ\nАналитический раздел предназначен для определения конкретных методов для реализации нейрокомпьютерного интерфейса, выявление преимуществ метода и инструментов для его применения. Также, раздел позволяет отобразить общую архитектуру системы, используя UML, и наглядно продемонстрировать интеграцию функциональных требований в общую модель бизнес-процесса, используя диаграммы SADT в нотации IDEF0. \nВыбор языка и инструментов программирования\nНа сегодняшний момент Python — это самый популярный язык по версии TIOBE, который известен своим упрощенным синтаксисом, что устраняет сложности при прочтении кода и делает его понятным для большего числа пользователей, желающих разобраться в работе [18]. Этот язык обладает обширным количеством библиотек, которые необходимы для реализации поставленной задачи и просты в использовании. Современные модели нейросетей написаны на этом языке, а также их сопроводительные документации и примеры использования.\nНиже приведены библиотеки, необходимые для реализации:\nPyLSL — библиотека для работы с Lab Streaming Layer, который позволяет считывать ЭЭГ сигналы с шлема в реальном времени.\nScipy — библиотека, позволяющая применять формулы высшей математики, а также работать с файлами MATLAB, в которых содержался набор данных для обучения модели.\nPandas — библиотека, предназначенная для работы с табличными данными. Использовалась для обработки данных для обучения.\nNumPy — библиотека, упрощающая вычислительные этапы.\nPyTorch — библиотека, необходимая для загрузки модели машинного обучения и дальнейшей работы с ней.\nRPI.GPIO — библиотека, позволяющая управлять каналами GPIO в одноплатном компьютере Raspberry Pi. В работе использовалась для обеспечения связи одноплатного компьютера с сервоприводом.\nВыбор метода классификации\nДля обработки табличных данных с целью определения движения рук была выбрана новая модель MetaTree, опубликованная в августе 2024 года в статье «Learning a Decision Tree Algorithm with Transformers» [19]. Ключевой особенностью данного подхода является использование двух алгоритмов для построения деревьев решений — CART (Classification and Regression Trees) и GOSDT (Gradient Optimized Stochastic Decision Trees), а также применение модели на основе трансформеров LLaMA (Large Language Model Meta AI). Трансформер в данной модели используется для генерации деревьев, учитывая связи между признаками. Данная модель работает с табличными данными, что упрощает предобработку и ускоряет прогнозирование.\nРазберем подробнее принцип работы нейросети. Архитектура нейросети представлена на Рисунке 2.1.\n\nРисунок 2.1 — Архитектура MetaTree\n После получения табличных данных, модель преобразовывает их в вектора для дальнейшей обработки. На этом этапе информация о признаках и их значениях преобразуется в формат, подходящий для обработки нейросетями. \nДалее применяется механизм внимания (attention mechanism), который проходит по строкам и столбцам данных с целью выявления зависимостей между признаками. \nМодель генерирует маску (One-hot mask), которая определяет признак, на основе которого данные различаются, а также определяет пороговое значение для ветвления. \nПроцесс обучения модели происходит в две фазы, которые представлены на Рисунке 2.2.\n\nРисунок 2.2 — Процесс обучения\nВо время первой фазы модель обучается для генерации деревьев решений GOSDT. Во время второй фазы добавляется модель CART. Объединение этих двух моделей способствует повышению качества классификации, так как они используют разные подходы. Первый метод минимизирует ошибки в построении, стремясь найти глобально оптимальное дерево, в то время как второй метод предназначен для классификации и не учитывает глобальную структуру дерева [20,21]. Использование трансформера для построения таких деревьев является современным решением, повышающим точность, так как оно подстраивается под особенности данных, учитывая их зависимость друг от друга.\nИспользование LSTM или CNN для представленной задачи могло бы вызвать проблемы с интерпретацией результатов. Данные архитектуры проигрывают набирающим популярность трансформерам, которые показывают лучшую производительность и скорость обучения. Более того, использование CNN предназначено для изображений и подразумевает преобразование первоначального вида табличных данных, что увеличивает скорость обработки данных [22,23,24].\nМодель бизнес-процесса в нотации IDEF0\nДля наглядного демонстрирования функциональных возможностей нейрокомпьютерного интерфейса предлагается моделирование бизнес-процесса в нотации IDEF0 [25]. Диаграммы SADT должны отображать все функциональные требования, которые были поставлены в исследовательском разделе [26].\nНа контекстном уровне представлен процесс использования нейрокомпьютерного интерфейса функциональных протезов, который преобразовывает данные ЭЭГ в подтверждение отправления команды, поступающие на сервопривод. \nВ качестве управляющих механизмов выступают «Руководство по эксплуатации» шлема NeoRec для считывания ЭЭГ сигналов, документация модели MetaTree, техническое задание и руководство по работе с сервоприводом. В качестве механизмов, обеспечивающих работу процесса, выступают программное обеспечение LSL, сервопривод, Bluetooth 5.0, скрипты, модель MetaTree и одноплатный компьютер. \nНа Рисунке 2.3 представлен контекстный уровень.\n\nРисунок 2.3 — Контекстный уровень «Преобразование данных ЭЭГ в отправленные команды»\nДекомпозиция контекстного уровня выявляет следующие процессы: обработка ЭЭГ сигналов, работа нейросети, обработка результатов нейросети. Декомпозиция контекстного уровня представлена на Рисунке 2.4.\n\nРисунок 2.4 — Декомпозиция контекстного уровня\nПроцесс «Обработка ЭЭГ сигналов» принимает на вход данные ЭЭГ, после чего преобразовывает их особые признаки. Механизмы, обеспечивающие данный процесс: LSL, одноплатный компьютер, скрипты и Bluetooth 5.0. Управляющими механизмами являются: техническое задание и руководство по эксплуатации NeoRec.\nПроцесс «Работа нейросети» принимает на вход 11 сигналов ЭЭГ и возвращает работу нейросети. Механизмы, обеспечивающие работу: модель MetaTree, одноплатный компьютер, скрипты. Управляющими механизмами являются: техническое задание и документация MetaTree.\nПроцесс «Обработка результатов нейросети» преобразует результат работы нейросети в подтверждение отправления команды. Механизмы, обеспечивающие работу: сервопривод, одноплатный компьютер, скрипты. Управляющими механизмами являются: техническое задание и руководство по работе с сервоприводом.\nДалее следует декомпозиция блока «Обработка ЭЭГ сигналов», которая представлена на Рисунке 2.5. \n\nРисунок 2.5 — Декомпозиция блока «Обработка ЭЭГ сигналов»\nПодпроцессами декомпозиции являются: подключение к LSL, считывание сигналов через Python, удаление лишних каналов, преобразование в признаки.\nПроцесс «Подключение к LSL» преобразует данные, собираемые шлемом ЭЭГ, в поток данных в реальном времени, поступающие на компьютер. Данный процесс управляется руководством по эксплуатации шлема, а механизмами являются одноплатный компьютер, LSL и Bluetooth 5.0.\nПроцесс «Считывание сигналов через Python» принимает на вход поток ЭЭГ данные в реальном времени, а затем используя встроенные библиотеки Python преобразует данные в организованный вид, считывая по одному сигналу с каждого из шестнадцати каналов. Управляет данным процессом руководство по эксплуатации NeoRec, в котором представлена ссылка на библиотеку Python, позволяющую считать данные. Механизмом является одноплатный компьютер.\nПроцесс «Удаление лишних сигналов, форматирование» преобразовывает 16 сигналов ЭЭГ в 11 сигналов. Механизмом являются скрипты и одноплатный компьютер, а управляющим механизмом техническое задание. \nНа Рисунке 2.6 представлена декомпозиция блока «Обработка результатов нейросети», которая разбивает блок на подпроцессы: определение команды для серводвигателя, проверка ШИМ-соединения, отправление команды. \n\nРисунок 2.6 — Декомпозиция блока «Обработка результатов нейросети»\nНа вход процессу «Определение команды для серводвигателя» поступает результат работы нейросети, который преобразовывается в управляющую команду. Процесс управляется техническим заданием, а в качестве механизма выступают скрипты и одноплатный компьютер.\nПроцесс «Проверка ШИМ-соединения» определяет статус соединения при получении управляющей команды. Процесс управляется руководством по работе с сервоприводом и использует следующие механизмы: сервопривод, скрипты и одноплатный компьютер. \nПроцесс «Отправление команды» преобразовывает статус соединения и управляющую команду в подтверждение отправления команды. Механизмами являются одноплатный компьютер, серводвигатель и скрипы, а управляющим механизмом руководство по работе с сервоприводом.\nАрхитектура системы\nДля отражения архитектуры системы, наиболее верным вариантом является диаграмма развертывания, так как отражает не только программные компоненты, но и физические ресурсы [27]. \nОсновным устройством в системе является одноплатный компьютер Raspberry Pi, на котором будет храниться скрипт и файлы, которые являются результатом обучения модели. Скрипт использует эти файлы для создания предсказания и отправления соответствующих команд. Все файлы находятся в виртуальной среде python3-venv, которая обеспечивает запуск кода с расширением .py. \nNeoRec Cap 16 — это шлем, для считывания ЭЭГ сигналов, который имеет ЭЭГ-усилитель со встроенным Bluetooth-адаптером. Одноплатный компьютер взаимодействует с шлемом посредством Bluetooth 5.0. В качестве соединения представлен интерфейс, предоставляющий данные ЭЭГ ЭЭГ-усилителем и передающий данные на компьютер.\nТак как модель распознает поднятие правой и левой рук, предполагается возможность управления двумя протезами. На диаграмме представлено два протеза, каждый из которых оснащен своим сервомотором. Сервомоторы подключены к компьютеру с помощью портов GPIO.\nНа Рисунке 2.7 представлена диаграмма развертывания.\n\nРисунок 2.7 — Диаграмма развертывания\nВывод по аналитическому разделу\nВ ходе работы над разделом был выбран эффективный метод обработки ЭЭГ сигналов, обоснована его актуальность и подобраны специальные инструменты для упрощения работы с методом, такие как язык программирование и библиотеки. Была отражена полноценная архитектура, в которой будет запускаться программное обеспечение, с помощью диаграммы развертывания. Большая часть раздела была посвящена визуализации работы системы в нотации IDEF0, которая отражает функциональность и соответствие требованиям технического задания. \nТЕХНОЛОГИЧЕСКИЙ РАЗДЕЛ\nВ данном разделе описана реализация нейронной сети и обеспечение взаимодействия с ней в режиме отладки и в режиме полноценной системы. Также подробно рассмотрена архитектура, которая использовалась при обучении модели. После реализации, наглядно продемонстрирован результат работы системы и некоторые ошибки, выявленные в ходе реализации. Данный раздел также подразумевает расчет надежности тем методом, который лучше всего подходит системе. В завершении раздела представлена пользовательская документация, которая упрощает развертку системы на стороннем оборудовании.\nПодготовка данных для обучения нейросети\nДля обучения нейросети был взят набор данных, представленный Бенджамином Бланкерцом для проведения конкурса среди исследователей в сфере интерфейсов мозг-компьютер. В выбранном наборе содержатся сигналы по каждому из 59 каналов ЭЭГ с временными метками, на которых определены движения правой и левой рук, а также ног. Данные представлены в виде нескольких файлов в расширении .mat [28]. \nБыла разработана программа для конвертации всех исходных файлов в один csv файл, в котором была произведена дополнительная обработка. Периодам бездействия был присвоен класс 0, а периодам активности правой и левой рук, как целевым классам было присвоено значение 1 и 2 соответственно. Также, общее количество каналов было урезано до 13, чтобы соответствовать набору каналов, присутствующих в шлеме Neorec Cap 16, а именно: 'O1', 'O2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'T7', 'T8', 'Fz', 'Cz', 'Pz' [29].\nИз общего количество доступных каналов были выбраны только каналы, отвечающие за лобную, центральную, сенсомоторную и затылочную долю — 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2'. Это было сделано, для повышения точности при обучении модели, так как эти каналы более всего задействованы в поднятии правой или левой руки.\nДля усиления различия между классами, датасет был преобразован следующим образом: были выделены информативные признаки, основанные на спектральных и пространственных характеристиках активности мозга. Колебания фиксируются в различных частотных диапазонах и отвечают за различный характер поведения:\nМю-ритм (8-13 Гц) — подавляется при моторной активности и ее мысленном представлении;\nБета-ритм (13-30 Гц) — отражает когнитивную и моторную активность;\nАльфа-ритм (8-13 Гц) — доминирует в состоянии покоя;\nГамма-ритм (30-100 Гц) — связан с когнитивными процессами и вниманием [30].\nС учетом различных диапазонов, были выявлены следующие признаки: C3_beta, C4_beta, C3_mu, F3_beta, F4_beta, F3_F4_asymmetry, motor_cortex_diff, P3_P4_alpha_diff.\nВ основном, признаки рассматриваются в частотах бета-ритма для выявления моторной активности. Признаки для левой и правой руки будут противоположны за счет межполушарной асимметрии, что увеличит разницу между классами. Такие признаки, как F3_F4_asymmetry, motor_cortex_diff, P3_P4_alpha_diff, являются разницей между F3_beta и F4_beta, C3_beta и C4_beta, P3_alpha и P4_alpha соответственно. Различия этих признаков указывают на то, что моторные команды для правого и левого полушария выполняются с различием.\nПосле обработки признаков и удаления шумовых данных из датасета общее количество строк, присутствующих в файле, составляет 2101, а размер файла 249 КБ, при изначальном размере фала 84 МБ. Данный набор является оптимальным, так как при расширении обучающего набора данных, точность модели не возрастала.\nОбучение нейронной сети\nДля использования выбранной модели MetaTree необходимо установить библиотеку metatreelib. Перед описанием процесса обучения, важно подробнее рассмотреть архитектуру. В предыдущей главе было упомянуто, что модель комбинирует в себе два вида алгоритмов, которые строят деревья — CART и GOSDT. \nПервая модель является мощным инструментом классификации, так как строит бинарные деревья, в которых каждый узел разбивается на двух потомков. Разбиение на два узла означает присутствие или отсутствие того или иного признака, что дает гарантию выявления всех признаков. В алгоритме предусмотрен механизм отсечения некоторых узлов для упрощения дерева и избежания переобучения. \nК сожалению, алгоритм не учитывает оптимальность построения и склонен к переобучению при большом количестве ветвей, поэтому его дополняет GOSDT. Таким образом, второй алгоритм строит оптимальные решения, помогая получить более точный результат, в то время как первый алгоритм может остановиться не на самом лучшем решении из-за принципа работы жадных алгоритмов.\nДля объединения лучших качеств двух моделей была использована модель Llama3, которая была выпущена 18 апреля 2024 года [31, 32].  Это трансформер-подобная модель, архитектура которой требует рассмотрения. \nПри поступлении входных данных, каждое слово преобразуется в векторное представление, которое разбивается на три вектора Query(Q), Key(K), Value(V) после нормализации RMS Norm. \nТри вектора поступают на вход механизму самовнимания, самому важному компоненту всех трансформеров, который позволяет учитывать взаимосвязь токенов. Полученное контекстное представление нормализуется и проходит через прямое распространение с функцией активации SwiGLU, генерируя выходные данные [33]. \nИспользуемая функция активации выражается следующей формулой (3.1):\n\n\t.\t(3.1)\n\nВ данной функции W и V матрицы весов, а c и b смещения. Функция Swish выражается формулой (3.2), где  — наклон:\n\n\t.\t(3.2)\n\nПосле прохождения прямого распространения выполняется нормализация и данные поступают на полносвязный слой для линейного преобразования в другую размерность. \nПоследним выходным слоем является функция активации, в частности функция Softmax, выраженная формулой (3.3), которая преобразовывает выходные данные в вероятностное распределение:\n\n\n\nгде\t — многопеременная логистическая функция;\n — входной вектор;\n — экспоненциальная функция для входа; \n — количество классов; \n — экспоненциальная функция для выхода.\nМодель использует ротационное позиционное кодирование, что представляет собой эффективный подход для улучшения восприятия и обработки последовательных данных, так как позволяет модели лучше захватывать зависимости между элементами последовательности, независимо от того, как долго они находятся друг от друга в контексте. \nНа Рисунке 3.1 представлена архитектура модели, где N — количество слоев, а x — параметры. \n\nРисунок 3.1 — Архитектура LLaMa3\nВ модели MetaTree были установлены следующие параметры для LLaMa3: количество слоев — 12, количество голов — 12, размерность векторного представления — 768.\nДля обучения модели потребовалось разделить набор данных на обучающую и тестовую выборку, где на обучающую пришлось 80% данных, а на тестовую 20%. В качестве target был выбран целевой класс, столбец y, в котором 2 отвечало за поднятие левой руки, 1 за поднятие правой руки и 0 за бездействие. Были определены следующие гиперпараметры модели: число тренировочных объектов (batch size) — 64, глубина деревьев — 3, количество классов — 3. Для повышения скорости работы модели, вычисления были переведены на GPU, где очищалась память для предотвращения ее полного заполнения. Модель обучалась в течении 15 минут. Полученные веса модели были сохранены в файл с расширением .pkl. Точность модели, определенная на тестовом наборе, составила 0.72.\nОбеспечение взаимодействия с протезом и шлемом\nОсновной задачей является считывание сигналов ЭЭГ с шлема NeoRec Cap 16, что обеспечивается библиотекой pylsl, которая способна получать данные в реальном времени по LSL-протоколу [34]. Так как в ходе написания работы не было возможности установить связь с реальным шлемом, была произведена имитация потока данных. \nДля отправки данных в поток использовалась функция StreamOutlet из библиотеки pylsl, а для получения данных функция StramInfo из той же библиотеки. \nС помощью библиотеки threading были произведены параллельные процессы, один из которых добавлял данные в поток с перерывом в 10 секунд, считывая данные ЭЭГ из файла csv, а другой получал данные из потока. Считанные сигналы ЭЭГ из потока отфильтровываются, оставляя только те сигналы, которые присутствовали в обучении. Также сигналы выстраиваются в необходимом порядке для правильной подачи значений на вход нейронной сети.\nОбученная модель подгружается из файлов model_structure.pth и model_weights.pth с помощью библиотеки torch. Прогноз модели производится по каждой строчке данных из потока и отображается в консоли. \nТак как предполагается связь одноплатного компьютера и сервомоторов посредством порта общего назначения (GPIO), необходимо добавить функцию отправки команд на сервомоторы по данному порту. Для этой цели использовалась библиотека pigpio, с помощью которой отправлялись команды по различным сценариям. \nДля имитационного тестирования был создан класс MockPigpio, чтобы сымитировать подключение сервомоторов, создав два экземпляра этого класса. Экземплярам были присвоены пины и изначальное положение в пространстве. \nПри прогнозе модели — 3 (состояние бездействия), сервомоторы приводятся в нейтральное положение. При прогнозе модели — 2, сервомотор правой руки поднимается, а второй сохраняет нейтральное положение. При прогнозе модели — 1, сервомотор левой руки поднимается, а второй сохраняет нейтральное положение. \nИзменение положения сервомоторов происходит благодаря функции set_servo_pulsewidth, которая отправляет команду на сервомотор при указании нового положения. \nПараллельные потоки находятся в ожидании завершения, после которого сбрасываются настройки сервомоторов. Исходный код представлен в приложении Б.\nТестирование\nПосле обеспечения связи со шлемом и сервомоторами, было протестировано отправление данных в поток, считывание данных, предсказание нейросети, составление управляющих команд и изменение положения сервомоторов. \nПоскольку тестирование происходило в имитационном режиме, отправление данных в поток и их получение происходило бесперебойно, однако при взаимодействии с реальным шлемом может случаться задержка или потеря данных в силу несовершенств передачи данных по Bluetooth 5.0. \nПередача данных по Bluetooth 5.0 не всегда бывает стабильной, особенно в условиях активного использования других беспроводных устройств, которые могут создавать помехи. Например, если рядом находятся другие Bluetooth-устройства или беспроводные сети, это может негативно отразиться на качестве передачи данных с шлема NeoRec Cap 16. В таких случаях может наблюдаться задержка в отправке и получении данных, что критично в задачах, требующих быстрого реагирования. Кроме того, технические ограничении самого шлема, такие как его емкость и обработка данных, также могут влиять на общую скорость и надежность взаимодействия.\nРабота нейронной сети имеет достаточно малую точность, что сказывается на частоте правильных предсказаний. На Рисунке 3.2 представлен результат имитационного тестирования, где каждый из компонентов демонстрирует исправную работу.\n\nРисунок 3.2 — Результат работы программы\nВ процессе разработки программного обеспечения использовалась среда интегрированной разработки (IDE) PyCharm. На Рисунке 3.3 представлены графические изображения найденных ошибок, которые могут служить основой для дальнейшего анализа и доработки системы.\n\nРисунок 3.3 — Обнаружение ошибок\nВ данной среде были выявлены некоторые ошибки и предупреждения, которые, хотя и не мешали прямой работе системы, тем не менее, могут вызвать дополнительные проблемы в будущем или привести к меньшей эффективности работы. Важно отметить, что эти ошибки требуют внимания, так как их исправление может существенно повысить надежность и производительность системы в целом. \nС помощью определенных сценариев необходимо проверить основной функционал программы. \nВ Таблице 3.1 представлен результат тестирования по созданию и завершению потоков. В данном тестовом сценарии показано, как создается поток, куда добавляются данные ЭЭГ, которые в последствии должны быть считаны с этого потока, после чего поток завершается. Каждый шаг тестового сценария был выполнен успешно.\nТаблица 3.1 — Тестовый сценарий по созданию и завершению потоков\nВ Таблице 3.2 представлен результат тестирования по фильтрации ЭЭГ-сигналов.  В данном тестовом сценарии были получены на вход все сигналы, среди которых были выделены лишь те, которые отвечают за движения рук. После этого, было подсчитано количество экземпляров каждого класса и записи были распределены поровну. При тестировании, каждый шаг был выполнен успешно.\nТаблица 3.2 — Тестовый сценарий по фильтрации ЭЭГ-сигналов\nВ Таблице 1.3 представлен тестовый сценарий по прогнозированию модели. В данном сценарии производилась проверка точности модели. На вход подавались сигналы ЭЭГ, у которых был известен исходный класс. Исходный класс сравнивался с предсказанием модели. Один из шагов оказался неуспешным введу малой точности модели.\nТаблица 3.3 — Тестовый сценарий по прогнозированию модели\nВ Таблице 3.4 представлен тестовый сценарий по отправке команд на сервомоторы. В данном сценарии на вход подавалось предсказание модели, на основе которого, на сервомотор передается соответствующая команда. При тестировании, каждый шаг был выполнен успешно.\nТаблица 3.4 — Тестовый сценарий по отправке команд на сервомоторы\nРасчет надежности\nЧтобы определить производительность системы и выявить самые уязвимые места, необходимо провести расчёт надежности. После анализа всех ошибок и оценки итогового влияния на систему, можно предпринять действия по улучшению качества модели. Для проведения расчёта существуют разные методы, необходимо определить тот, который лучше всего подходит к системе.\nМодель Коркорэна\nМодель Коркорэна является статистической моделью, которая более расширена, по сравнению с простыми методами оценки надежности, такими как временные модели надежности [35]. Особенностью модели является учет силы влияния разного типа ошибок.\nПри оценке надежности, данная модель учитывает несколько параметров, что особенно важно в сложных системах. \nРасчёт надежности происходит по формуле (3.4):\n\t\n\n\nгде      — число безотказных испытаний;\n — общее число испытаний;\n — количество ошибок i-го типа; \n — вероятность проявления ошибок i-го типа;\nk — известное число типов ошибок;\nR — показатель надежности.\nОбщее количество проведенных испытаний — 30, при этом безотказных 20. Во время тестирования были выявлены некоторые типы ошибок, которые были отражены в Таблице 3.5.\nТаблица 3.5 — Вероятности ошибок\nРассчитав надежность по формуле (3.4):\n\n\n\nможно утверждать, что написанная программа будет выполняться корректно с вероятностью 0,698.\nМодель Миллса\nИспользование модели Миллса подразумевает искусственное внесение некоторого количество ошибок в программу перед началом тестирования. Ошибки вносятся случайно, специалист не знает ни количество, ни характер внесенных ошибок. В процессе тестирования, естественные и искусственные ошибки равновероятно могут быть найдены в процессе тестирования. Программа тестируется в течении некоторого времени, после чего собираются статистические данные об обнаруженных ошибках.\nПусть после тестирования обнаружено  собственных ошибок программы и  искусственно внесенных. Тогда первоначальное число ошибок в программе можно оценить по формуле:\n\t\n\n\nгде      — количество искусственно внесенных ошибок.\nПосле искусственного внесения в программу 19 известных ошибок, было обнаружено 2 собственные и 17 внесенных ошибок, тогда по формуле (3.5) количество первоначальных ошибок соответствует:\n\n\n\nПредставленный способ расчета содержит в себе недостаток. Нахождение всех искусственных ошибок, гарантирует, что все естественные ошибки также найдены. Таким образом, при внесении малого количества искусственных ошибок, не все естественные ошибки могут быть обнаружены. Для решения данной проблемы была добавлена вторая часть модели.\nДопустим, в программе изначально  ошибок. В программу искусственно вносятся  ошибок и проводится тестирование, пока все внесенные ошибки не будут обнаружены. При тестировании также может быть обнаружено   собственных ошибок. Вероятность, что в программе изначально было  ошибок, можно рассчитать по следующему соотношению:\n\n\n\nПредположив, что в программе нет ошибок, необходимо проверить эту вероятность проведя расчет по формуле (3.6):\n\n\nТаким образом, с вероятностью 0,95 можно утверждать, что в программе нет ошибок.\nРуководство пользователя\nРуководство по использованию программного обеспечения приведено в двух вариантах. Первый вариант предназначен для проверки работоспособности при отсутствии шлема или протеза с сервомотором. Второй вариант использования соответствует полноценной работе системы.\nЭксплуатация в имитации\nПри отсутствии шлема ЭЭГ или сервомоторов предлагается проверить корректность работы программы следующим образом.\nУбедитесь, что на вашем устройстве установлены следующие библиотеки: threading, time, csv, torch, pylsl, pigpio. При их отсутствии, установите их с помощью команды pip install threading, time, csv, torch, pylsl, pigpio.\nУбедитесь, что файл с весами и файл со структурой обученной модели установлены и находятся в той же папке, что и программа. \nЗапустите программу с помощью команды run LSLwork.py.\nРеальная эксплуатация\nДля запуска программного обеспечения на Raspberry Pi, необходимо убедиться в наличии следующего оборудования: \nВстроенный или внешний Bluetooth-адаптер, который необходим для подключения к шлему.\n Один или два сервомотора, необходимые для управления движениями.\n Провода для подключения сервомоторов с GPIO пинами на Raspberry Pi.\nБлок питания для одноплатного компьютера.\nШлем NeoRec Cap 16 — устройство для считывания ЭЭГ сигналов.\nПеред началом работы с программным обеспечением, необходимо установить все необходимые программы и библиотеки, а также саму программу. Убедитесь, что в директории с программой находятся также файлы с моделью: model_structure.pth, model_weights.pth.\nПосле установки библиотеки для работы с Bluetooth, необходимо включить его с помощью команд - sudo systemctl start bluetooth и sudo systemctl enable bluetooth. Далее запустите утилиту для настройки — bluetoothctl. \nЧтобы найти доступные устройства для сопряжения, введите следующие команды: power on, agent on, scan on. Включите ЭЭГ-усилитель на шлеме. Проверьте, есть ли шлем NeoRec Cap 16 среди доступных устройств по MAC-адресу. Введите три следующие команды, вставляя MAC-адрес нужного устройства на месте иксов: pair X, connect X, trust X.\nПодключите сервомотор для правой руки на GPIO 17, а для левой на GPIO 18.\nДля запуска программы перейдите в директорию, в которой располагается программное обеспечение с помощью команды — cd /path/to/your/software.\nЗапустите программу с помощью команды — python3 LSLwork.py. После запуска программа должна автоматически предсказывать движения и управлять сервомоторами. При возникновении проблем, проверьте соединения и настройки Bluetooth.\nВывод по технологическому разделу\nВ ходе технологического раздела подробно обоснованы выбранные данные для обучения, а также разъяснено взаимодействие с выбранной архитектурой. Каждая используемая библиотека и каждая созданная функция были детально охарактеризованы. Реализованная система была протестирована на разных этапах работы: при формировании потока, считывании данных из потока, предсказании нейросети и формировании команд. Для каждого этапа тестирования был сформирован индивидуальный тестовый случай, что наглядно демонстрирует работу системы. После тестирования рассчитана надежность методом Коркорэна и Миллса. Также была сформирована пользовательская документация для эксплуатации системы при разных условиях.\nЭКОНОМИЕСКИЙ РАЗДЕЛ\nДанный раздел посвящен экономической части, которая позволяет оценить себестоимость, вклад всех участников проекта, проанализировать все расходы и выявить аспекты для оптимизации.\nОрганизация и планирование работ\nДля успешного выполнения проекта, в работе задействованы такие участники, как руководитель проекта, консультант и разработчик:\nРуководитель (Мусихин А.Г., доцент кафедры ВТ) — производит контроль всех этапов работы, отвечает за грамотную постановку задачи, внесение правок и оценивает качество работы в целом.\nКонсультант (Потрясаева Е.А., старший преподаватель) — производит контроль над организацией и планированием, проводит оценку и расчет стоимости работ.\nРазработчик (Сазонова А.В., студент группы ИКБО-04-21) — выполняет основную часть работы, такую как проектирование и разработку нейроинтерфейса, его тестирование и подготовку документации.\nНа схеме (Рисунок 4.1) представлены участники, задействованные в работе, и их взаимодействие.\n\nРисунок 4.1 — Схема участников\nОрганизация работ\nОрганизация планирования подразумевает определение содержание проекта, его декомпозиции, планирование последовательности работ и сроков. Общая продолжительность работ над созданием выпускной квалификационной работы составляет 90 дней. В Таблице 4.1 представлены все этапы разработки и участвующие в них исполнители.\nТаблица 4.1 — Этапы разработки\nПродолжение Таблицы 4.1\nГрафик проведения работ\nКалендарный график исполнения работы представлен в Таблице 4.2. Из Таблицы видно, что общий срок разработки составляет 90.\nТаблица 4.2 — График проведения работ\nРасчёт затрат на проведение работ\t\t\nРасчет себестоимости проведенных работ, производится путем сложения затрат по следующим пунктам:\nСырье и материалы;\nОсновная заработная плата;\nДополнительная заработная плата;\nСтраховые взносы;\nАмортизация;\nПрочие расходы.\nСырье и материалы\nВ пункте рассчитывается стоимость расходных материалов, полуфабрикатов, комплектующих, расходуемых непосредственно в процессе проектирования и разработки решения [36]. В стоимость также включаются транспортно-заготовительные расходы, которые занимают 10% стоимости затрат по пункту. В Таблице 4.3 собраны все расходные материалы.\nТаблица 4.3 — Стоимость материалов\nТаким образом, сумма затрат по пункту составит 5 478 рублей.\nОсновная заработная плата\nВ пункте определяется стоимость оплаты труда всех исполнителей, участвующих в выполнении работы. Дневная тарифная ставка рассчитывалась исходя из шестидневной рабочей недели [37]. В Таблице 4.4 представлен расчет заработной платы для каждого исполнителя.\nТаблица 4.4 — Основная заработная плата\nПродолжение Таблицы 4.4\nДополнительная заработная плата\nВ данной статье производится подсчет дополнительной выплаты, которая предусматривается законодательством под разные случаи. Дополнительная заработная плата (ДЗП) составляет 20-30% от суммы основной заработной платы. Таким образом, в данной работе ДЗП составляет 25% от общей суммы:\n\n\n\nФонд оплаты труда (ФОТ) представляет собой сумму основной и дополнительной зарплаты и равняется:\n\n\nСтраховые взносы\nПо закону, страховые выплаты (СВ) составляют 30% от фонда оплаты труда, однако, в расчете необходимо учесть ставку взносов на травматизм, которая для РТУ МИРЭА равняется 0,2% [38, 39]. Таким образом, размер страховых выплат составляет 30,2% от фонда оплаты труда:\n\n\nАмортизация\nДля возмещения износа используемого оборудования, стоимость которого превышает 100 тысяч рублей, необходимо рассчитать размер амортизационных отчислений [40]. В Таблице 4.5 представлены амортизационные отчисления.\nТаблица 4.5 — Амортизационные отчисления\nПрочие расходы\nРасчет прочих расходов (ПР) принято определять процентом от суммы основной заработной платы в диапазоне от 100 до 130%. К прочим расходам относятся расходы на содержание и ремонт зданий, оборудования, инвентаря. При 105% прочие расходы будут равняться:\n\n\nПолная себестоимость работ\nВ Таблице 4.6 обобщаются определенные выше затраты по следующим статьям: сырье и материалы, основная заработная плата, дополнительная заработная плата, страховые взносы, амортизация, прочие расходы. Также посчитана доля каждой статьи из общей суммы затрат.\nТаблица 4.6 — Полная себестоимость работ\nНа Рисунке 4.2 представлена круговая диаграмма, которая отражает долевой состав затрат в общей себестоимости.\n\nРисунок 4.2 — Структура затрат по работе\nТаким образом, договорная цена (ДЦ) рассчитана путем сложения себестоимости, прибыли, и НДС (20%), где прибыль составляет 10% от стоимости разработки:\n\n\nЗАКЛЮЧЕНИЕ\nОсновной целью дипломной работы было создание нейроинтерфейса, который работает на отечественном оборудовании, быстро обрабатывает сигналы ЭЭГ при помощи методов машинного обучения, предсказывая движения руки, и отправляет управляющие команды на сервомоторы, которые, в свою очередь, отвечают за поднятие ручного протеза соответствующей руки. Данный проект позволяет расширить возможности людей с ограничениями, а также пополняет список разработок в области человек-машина. В ходе работы все поставленные цели были достигнуты, а также удовлетворены все установленные требования. \nThe primary objective of the thesis was to develop a brain-computer interface that operates on domestically produced hardware, rapidly processes EEG signals using machine learning methods, predicts arm movements, and sends control commands to servomotors responsible for lifting the corresponding hand prothesis. This project enhances the capabilities of people with disabilities, and also adds to the list of developments in the field of human-machine. Throughout the work, all set goals were achieved, as well as all the established requirements were met.\n\n\nСПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ\nГОСТ Р ИСО/МЭК 12207-2010 Информационная технология. Системная и программная инженерия. Процессы жизненного цикла программных средств [Электронный ресурс] — Режим доступа: https://docs.cntd.ru/document/ 1200082859 (дата обращения: 17.03.2025).\nГОСТ Р ИСО/МЭК 15504-5-2016 Информационные технологии. Оценка процессов. Часть 5. Образец модели оценки процессов жизненного цикла программного обеспечения [Электронный ресурс] — Режим доступа: https://docs.cntd.ru/document/1200141154 (дата обращения: 17.03.2025).\nФедеральный закон «О защите населения и территории от чрезвычайных ситуаций природного и техногенного характера» (последняя редакция) [Электронный ресурс] — Режим доступа: https://www.consultant.ru/document/cons_doc_LAW_5295/ (дата обращения: 17.03.2025).\nФедеральный закон «Об основах охраны здоровья граждан в Российской Федерации» (последняя редакция) [Электронный ресурс] — Режим доступа: https://minzdrav.gov.ru/documents/7025-federalnyy-zakon-323-fz-ot-21 noyabrya-2011-g (дата обращения: 17.03.2025).\nФедеральный закон «О гражданской обороне» [Электронный ресурс] — Режим доступа: https://www.consultant.ru/document/cons_doc_LAW_17861/ (последняя редакция) (дата обращения: 17.03.2025).\nПриказ Минздравсоцразвития РФ от 04.05.12 № 447н «Об утверждении перечня состояний, при которых оказывается первая помощь, и перечня мероприятий по оказанию первой помощи» (ред. от 07.11.2012) [Электронный ресурс] — Режим доступа: https://www.consultant.ru/document/cons_doc _LAW_129862/ (дата обращения: 17.03.2025).\nТрудовой Кодекс Российской Федерации (ред. от 04.08.2023, с изм. от 24.10.2023) [Электронный ресурс] — Режим доступа: https://www.consultant.ru/document/cons_doc _LAW_34683/ (дата обращения: 17.03.2025).\nСанПин 2.2.2/542-96 «Гигиенические требования к видеодисплейным терминалам, персональным электронно-вычислительным машинам и организации работы» [Электронный ресурс] — Режим доступа: https://docs.cntd.ru/document/5200235 (дата обращения: 17.03.2025).\nRitam Ghosh. A Survey of Brain Computer Interface Using Non-Invasive Methods [Электронный ресурс] — Режим доступа: https://arxiv.org/abs/2309.13151 (Дата обращения: 04.03.2025).\nMd. Kafiul Islam. Editorial: Recent advances in EEG (non-invasive) based BCI applications [Электронный ресурс] — Режим доступа: https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2023.1151852/full (дата обращения: 04.03.2025).\nSaidul Islam. A Comprehensive Survey on Applications of Transformers for Deep Learning [Электронный ресурс] — Режим доступа: https://arxiv.org/abs/2306.07303 (дата обращения: 04.03.2025).\nЛ.Д. Маркина, А.А. Баркар. Межполушрная ассиметрия головного мозга: морфологический и физиологический аспекты [Электронный ресурс] — Режим доступа: https://cyberleninka.ru/article/n/mezhpolusharnaya-asimmetriya-golovnogo-mozga-morfologicheskiy-i-fiziologicheskiy-aspekty (дата обращения: 30.11.2024).\nNeuralink [Электронный ресурс] — Режим доступа: https://neuralink.com/blog/prime-study-progress-update-second-participant/ (дата обращения: 30.11.2024).\nOpenBCI, S.A.P.I.E.N.S [Электронный ресурс] — Режим доступа: https://openbci.com/community/s-a-p-i-e-n-s-sensor-aided-prosthesis-integrating-electrophysiology-neural-systems (дата обращения: 30.11.2024).\nEmotiv [Электронный ресурс] — Режим доступа: https://www.emotiv.com/products/emotiv-bci (дата обращения: 30.11.2024).\nAbhinav Chinta, Mayank Mathur, Anisha M. Lal. Mind Wave Controlled Prosthetic ARM Without using Brain Implants [Электронный ресурс] — Режим доступа: https://www.ijrte.org/wp-content/uploads/papers/v8i5/E4801018520.pdf (дата обращения: 30.11.2024).\nГОСТ 34.602-89 Техническое задание на создание автоматизированной системы [Электронный ресурс] — Режим доступа: www.rugost.com/index.php?option=com_content&view=article&id=96:gost-34602-89&catid=22&Itemid=53 (дата обращения: 17.03.2025).\nИндекс TIOBE [Электронный ресурс] — Режим доступа: https://www.tiobe.com/tiobe-index/ (дата обращения: 04.12.2024).\nLearning a Decision Tree Algorithm with Transformers [Электронный ресурс] — Режим доступа: https://arxiv.org/pdf/2402.03774/ (дата обращения: 04.12.2024).\nАлгоритм CART [Электронный ресурс] — Режим доступа: https://ru.wikipedia.org/wiki/CART_(алгоритм) (дата обращения: 04.12.2024).\nАлгоритм GOSDT [Электронный ресурс] — Режим доступа: https://users.cs.duke.edu/~cynthia/CourseNotes/ModernDecisionTreeNotes.pdf (дата обращения: 04.12.2024).\nАрхитектура LSTM [Электронный ресурс] — Режим доступа: https://ru.wikipedia.org/wiki/Долгая_краткосрочная_память (дата обращения: 04.12.2024).\nАрхитектура CNN [Электронный ресурс] — Режим доступа: https://ru.wikipedia.org/wiki/Свёрточная_нейронная_сеть#:~:text=convolutional%20neural%20network%2C%20CNN)%20—,в%20состав%20технологий%20глубокого%20обучения. (дата обращения: 04.12.2024).\nАрхитектура трансформера [Электронный ресурс] — Режим доступа: https://ru.wikipedia.org/wiki/Трансформер_(модель_машинного_обучения) (дата обращения: 04.12.2024).\nНотация IDEF0 [Электронный ресурс] — Режим доступа: ttps://www.businessstudio.ru/wiki/docs/current/doku.php/ru/csdesign/bpmodeling/idef0 (дата обращения: 04.12.2024).\nSADT [Электронный ресурс] — Режим доступа:  https://ru.wikipedia.org/wiki/SADT (дата обращения: 04.12.2024).\nДиаграмма развертывания [Электронный ресурс] — Режим доступа:   https://creately.com/blog/ru/uncategorized-ru/учебное-пособие-по-диаграмме-развёрт/ (дата обращения: 04.12.2024).\nНабор данных Dataset 1 BCI Competition VI [Электронный ресурс] — Режим доступа: https://www.bbci.de/competition/iv/desc_1.html (дата обращения: 04.12.2024).\nШлем NeoRec Cap 16 [Электронный ресурс] — Режим доступа: https://mcscap.ru/catalog/mobilnaya-sistema-neorec/sistema-neorec-cap-base/ (дата обращения: 04.12.2024).\nThe Berlin Brain-Computer Interface: Machine learning-based detection of user-specific brain states [Электронный ресурс] — Режим доступа: https:// www.researchgate.net/publication/203917744_The_Berlin_Brain-Computer_Interface_Machine_Learning_Based_Detection_of_User_Specific_Brain_States (дата обращения: 04.12.2024).\nLlama3 [Электронный ресурс] — Режим доступа: https://www.ultralytics.com/ru/blog/getting-to-know-metas-llama-3 (дата обращения: 04.12.2024).\nLlama3 [Электронный ресурс] — Режим доступа: https://habr.com/ru/articles/879468/ (дата обращения: 04.03.2025).\nSwiGLU [Электронный ресурс] — Режим доступа: https://jcarlosroldan.com/post/348 (дата обращения: 04.03.2025).\nLSL-протокол [Электронный ресурс] — Режим доступа:  https://labstreaminglayer.readthedocs.io/info/intro.html (дата обращения: 04.03.2025).\nМодель Коркорэна [Электронный ресурс] — Режим доступа: https:// mydocx.ru/2-105752.html?ysclid=m51a1fq9v3771317666 (дата обращения: 04.12.2024).\nНалоговый кодекс Российской Федерации (часть вторая) от 05.08.2000 № 117-ФЗ (ред. от 13.12.2024). Статья 254. Материальные расходы [Электронный ресурс]. — Режим доступа: https://www.consultant.ru/document/cons_doc_LAW_28165/0644a51c8d171aad7127867a97d0749ec20be875/ (дата обращения: 17.03.2025). \nПроизводственный календарь на 2025 г. [Электронный ресурс] —  Режим доступа: https://nalog-nalog.ru/proizvodstvennyj_kalendar/2025-6/  (дата обращения: 17.03.2025).\nЕдиный тариф (единые размеры) страховых взносов на ОПС, ОСС, ОМС для плательщиков, производящих выплаты физическим лицам, на 2025 г. [Электронный ресурс] — Режим доступа: https://www.consultant.ru/document/cons_doc_LAW_93256/97a8d65271700b79d87a7edf33832b5f3ce0fd18/ (дата обращения: 17.03.2025).\nПриказ Минтруда России от 30.12.2016 N 851н (ред. от 29.08.2024) \"Об утверждении Классификации видов экономической деятельности по классам профессионального риска\" (Зарегистрировано в Минюсте России 18.01.2017 N 45279) [Электронный ресурс] — Режим доступа: https://www.consultant.ru/document/cons_doc_LAW_211247/ (дата обращения: 17.03.2025).\nНалоговый кодекс Российской Федерации (часть вторая) от 05.08.2000 № 117-ФЗ (ред. от 13.12.2024). Статья 256. Амортизируемое имущество [Электронный ресурс] — Режим доступа: https://www.consultant.ru/document/cons_doc_LAW_28165/df53ee1751d3e93dbf8c0d34076675da18a2fd06/ (дата обращения: 11.04.2025). \n\nПРИЛОЖЕНИЯ\nПриложение А — Презентация\nПриложение Б — Исходный код\n\n\nПриложение А\nПрезентация\nНа Рисунке А.1 представлен слайд с титульным листом.\n\nРисунок А.1 — Титульный лист\nНа Рисунке А.2 представлен слайд, который обосновывает актуальность.\n\nРисунок А.2 — Актуальность\nНа Рисунке А.3 представлен слайд, на котором обозначена основная цель работы, а также перечислены все поставленные задачи.\n\nРисунок А.3 — Цели и задачи\nНа Рисунке А.4 отображен один из неинвазивных способов получения сигналов мозга. На рисунке изображены места расположения электродов, используемых при электроэнцефалографии.\n\nРисунок А.4 — Неинвазивный подход\nНа Рисунке А.5 представлен слайд, на котором перечислен основной реализованный функционал.\n\nРисунок А.5 — Основной функционал\nНа Рисунке А.6 представлен слайд, где перечислены все существующие аналоги, а также все их достоинства и недостатки. При оценке учитывались следующие качества: простота, доступность в России, качество, бесплатное использование, открытый исходный код.\n\nРисунок А.6 — Сравнение с аналогами\nНа Рисунке А.7 представлен слайд, на котором прикреплена диаграмма развертывания для обозначения архитектуры системы.\n\nРисунок А.7 — Архитектура системы\nНа Рисунке А.8 слайд с архитектурой используемой модели — MetaTree. Модель содержит в себе два вида деревьев: GOSDT и CART. На основе двух этих алгоритмов, модель учится строить наиболее оптимальные деревья.\n\nРисунок А.8 — Архитектура MetaTree\nНа Рисунке А.9 представлен слайд, на котором изображена архитектура LLaMa, которая построена на основе трансформеров.\n\nРисунок А.9 — Архитектура LLaMa\nНа Рисунке А.10 изображен слайд с тестированием. На рисунке видно, какие данные отправляются в поток, какое предсказание было сделано на основе полученных данных, а также виден истинный класс.\n\nРисунок А.10 — Тестирование\nНа Рисунке А.11 представлен слайд с расчетом надежности, а также результаты расчетов по экономической части.\n\nРисунок А.11 — Расчеты надежности и экономики\nНа Рисунке А.12 представлен слайд, где отображена практическая значимость работы и перспективы развития\n\nРисунок А.12 — Заключение\nНа Рисунке А.13 представлен слайд со всеми достижениями, которые помогли с выбором наиболее подходящей модели машинного обучения для разработанной системы.\n\nРисунок А.13 — Достижения\nНа Рисунке А.14 представлен финальный слайд.\n\nРисунок А.14 — Финальный слайд\nПриложение Б\nИсходный код\nЛистинг Б.1 — Файл LSLwork.py\nimport threading\nimport time\nimport csv\nimport torch\nfrom pylsl import StreamInfo, StreamOutlet, StreamInlet, resolve_stream\nimport pigpio\nimport warnings\nimport logging\nimport numpy as np\nfrom scipy import signal, stats\nimport pywt\n# Цвета для вывода\nclass Colors:\n    HEADER = '\\033[95m'\n    BLUE = '\\033[94m'\n    CYAN = '\\033[96m'\n    GREEN = '\\033[92m'\n    YELLOW = '\\033[93m'\n    RED = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n# Имитируемая pigpio библиотека\nclass MockPigpio:\n    def __init__(self):\n        self.servo_positions = {17: 1500, 18: 1500}  # Устанавливаем начальные позиции\n\n    def set_servo_pulsewidth(self, pin, pulsewidth):\n        if self.servo_positions[pin] != pulsewidth:\n            self.servo_positions[pin] = pulsewidth\n            position = \"поднята\" if pulsewidth == 2000 else \"опущена\" if pulsewidth == 1000 else \"в среднем положении\"\n            print(f\"{Colors.CYAN}Сервопривод на пине {pin}: {Colors.GREEN}{position} {Colors.ENDC}({pulsewidth} мкс)\")\n\n    def stop(self):\n        print(f\"{Colors.YELLOW}Сервоприводы остановлены{Colors.ENDC}\")\n# Использование MockPigpio вместо pigpio для имитации\npi = MockPigpio()\n# Настройка сервомоторов\npi.set_servo_pulsewidth(17, 1500)  # Средняя позиция для сервомотора на пине 17\npi.set_servo_pulsewidth(18, 1500)  # Средняя позиция для сервомотора на пине 18\n\ndef control_servos(prediction):\n    if prediction == 3:\n        print(f\"{Colors.GREEN}Обе руки опущены{Colors.ENDC}\")\n        pi.set_servo_pulsewidth(17, 1500)  # Средняя позиция\n        pi.set_servo_pulsewidth(18, 1500)  # Средняя позиция\n    elif prediction == 2:\n        print(f\"{Colors.GREEN}Правая рука поднята, левая опущена{Colors.ENDC}\")\n        pi.set_servo_pulsewidth(17, 2000)  # Позиция поднятой правой руки\n        pi.set_servo_pulsewidth(18, 1500)  # Средняя позиция для левой руки\n    elif prediction == 1:\n        print(f\"{Colors.GREEN}Левая рука поднята, правая опущена{Colors.ENDC}\")\n        pi.set_servo_pulsewidth(17, 1500)  # Средняя позиция для правой руки\nПродолжение Листинга Б.1\npi.set_servo_pulsewidth(18, 2000)  # Позиция поднятой левой руки\n# Определение нужных каналов и их индексов\nchannels_to_keep = ['F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2']\nall_channels = ['Fp1','Fp2','F3','F4','C3','C4','P3','P4','O1','O2','A1','A2','F7','F8','T3','T4','T5','T6','Fz','Cz','Pz','X5','y']\nchannels_indices = [all_channels.index(channel) for channel in channels_to_keep]\n# Функции извлечения признаков\ndef apply_filters(data, fs=250):\n    \"\"\"Применение фильтров к сигналу ЭЭГ\"\"\"\n    b, a = signal.butter(4, [8.0, 30.0], btype='bandpass', fs=fs)\n    filtered = signal.filtfilt(b, a, data)\n    coeffs = pywt.wavedec(filtered, 'db4', level=4)\n    return pywt.waverec(coeffs[:-2], 'db4')\ndef extract_features_from_sample(sample_data, fs=250):\n    \"\"\"Извлечение признаков из одного сэмпла данных\"\"\"\n    features = {}\n        # Создаем словарь с данными каналов\n    channel_data = {\n        'F3': sample_data[all_channels.index('F3')],\n        'F4': sample_data[all_channels.index('F4')],\n        'C3': sample_data[all_channels.index('C3')],\n        'C4': sample_data[all_channels.index('C4')],\n        'P3': sample_data[all_channels.index('P3')],\n        'P4': sample_data[all_channels.index('P4')],\n        'O1': sample_data[all_channels.index('O1')],\n        'O2': sample_data[all_channels.index('O2')]\n    }\n        # Обработка моторных и фронтальных каналов\n    for ch in ['C3', 'C4', 'F3', 'F4']:\n        # Используем простое значение вместо фильтрации для одного сэмпла\n        signal_data = channel_data[ch]\n        \n        # Спектральные характеристики\n        features.update({\n            f'{ch}_beta': signal_data  # Используем значение напрямую\n        })\n        if ch in ['C3', 'C4']:\n            features.update({\n                f'{ch}_mu': signal_data,  # Используем значение напрямую\n                f'{ch}_std': 0  # Для одного значения std = 0\n            })\n        # Межканальные признаки\n    c3_beta = features['C3_beta']\n    c4_beta = features['C4_beta']\n    features.update({\n        'C3_C4_beta_ratio': c3_beta / (c4_beta + 1e-6),\n        'F3_F4_asymmetry': (features['F3_beta'] - features['F4_beta']) /\n                          (features['F3_beta'] + features['F4_beta'] + 1e-6),\n        'motor_cortex_diff': np.abs(c3_beta - c4_beta),\n        'C3_C4_crosscorr': channel_data['C3'] * channel_data['C4']  # Упрощенная корреляция для одного значения\n    })\n        # Обработка теменных и затылочных каналов\n    for ch in ['P3', 'P4', 'O1', 'O2']:\n        signal_data = channel_data[ch]\n            features.update({\n            f'{ch}_alpha': signal_data,  # Используем значение напрямую\n            f'{ch}_gamma': signal_data,  # Используем значение напрямую\n            f'{ch}_hjorth_mobility': 0  # Для одного значения мобильность не имеет смысла\nПродолжение Листинга Б.1\n})\n        # Межканальные отношения\n    features.update({\n        'P3_P4_alpha_diff': features['P3_alpha'] - features['P4_alpha'],\n        'Occipital_gamma_mean': np.mean([features['O1_gamma'], features['O2_gamma']])\n    })\n        # Преобразуем признаки в вектор в том же порядке, что и в preprocess.py\n    feature_vector = np.array([\n        features['C3_beta'], features['C4_beta'], features['C3_mu'],\n        features['F3_beta'], features['F4_beta'],\n        features['F3_F4_asymmetry'],\n        features['motor_cortex_diff'],\n        features['C3_C4_crosscorr'],\n        features['P3_P4_alpha_diff'],\n        features['Occipital_gamma_mean']\n    ])\n        return feature_vector\nwith open('MetaTree/model_weights.pth', 'rb') as file:\n    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n    # Загрузка всей структуры модели\n    model = torch.load('MetaTree/model_structure.pth')\n    model.eval()\n    # Загрузка весов модели\n    model.load_state_dict(torch.load('MetaTree/model_weights.pth'))\n    model.eval()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model = model.to(device)\ndef simulate_eeg_data():\n    info = StreamInfo('EEG', 'EEG', 23, 100, 'float32', 'myuid34234')\n    outlet = StreamOutlet(info)\n    with open('MetaTree/A1_Test.csv', 'r') as file:\n        reader = csv.reader(file)\n        next(reader, None)  # Пропускаем заголовок, если он есть\n\n        for row in reader:\n            eeg_data = [float(value) for value in row]\n            outlet.push_sample(eeg_data)\n            print(f\"Отправлено: {eeg_data}\")\n            time.sleep(1)\n\ndef read_eeg_data():\n    streams = resolve_stream('type', 'EEG')\n    inlet = StreamInlet(streams[0])\n    print(f\"{Colors.BOLD}{Colors.BLUE}=== Подключение к потоку установлено. Начинаю чтение данных... ==={Colors.ENDC}\\n\")\n    while True:\n        sample, timestamp = inlet.pull_sample()\n        if sample is None:\n            continue\n          \n        # Вывод исходных данных\n        channel_data = {ch: sample[all_channels.index(ch)] for ch in channels_to_keep}\n        print(f\"{Colors.CYAN}Каналы:{Colors.ENDC} \" + \" | \".join([f\"{ch}: {val:.3f}\" for ch, val in channel_data.items()]))       \n        # Извлекаем признаки из текущего сэмпла\n        feature_vector = extract_features_from_sample(sample)\n           # Вывод признаков\n        feature_names = [\n            'C3_beta', 'C4_beta', 'C3_mu',\nПродолжение Листинга Б.1\n'F3_beta', 'F4_beta',\n            'F3_F4_asymmetry',\n            'motor_cortex_diff',\n            'C3_C4_crosscorr',\n            'P3_P4_alpha_diff',\n            'Occipital_gamma_mean'\n        ]\n        \n        print(f\"{Colors.CYAN}Признаки:{Colors.ENDC} \" + \" | \".join([f\"{name}: {val:.3f}\" for name, val in zip(feature_names, feature_vector)]))\n        \n        # Преобразуем признаки в тензор и передаем в модель\n        input_tensor = torch.tensor(feature_vector, dtype=torch.float32).unsqueeze(0).to(device)\n        \n        # Получаем предсказание модели\n        result = model.predict(input_tensor)\n        result = result.argmax(dim=-1).squeeze().cpu().numpy()\n        result = result + 1\n        \n        # Получаем истинный класс\n        y = int(sample[-1])\n              print(f\"{Colors.BOLD}{Colors.BLUE}=== Результаты классификации ==={Colors.ENDC}\")\n        print(f\"{Colors.CYAN}Предсказанный класс:{Colors.ENDC} {Colors.GREEN}{result}{Colors.ENDC}\")\n        print(f\"{Colors.CYAN}Истинный класс:{Colors.ENDC} {Colors.GREEN}{y}{Colors.ENDC}\")\n        \n        # Управляем сервоприводами\n        control_servos(result)\n        print(f\"\\n{Colors.YELLOW}{'='*50}{Colors.ENDC}\\n\")\n\n# Создаем потоки для обеих функций\nthread1 = threading.Thread(target=simulate_eeg_data)\nthread2 = threading.Thread(target=read_eeg_data)\n\nlogging.disable(logging.WARNING)\nlogging.disable(logging.INFO)\n\n# Запускаем потоки\nthread1.start()\nthread2.start()\n\n# Ожидание завершения работы потоков (опционально)\nthread1.join()\nthread2.join()\n\n# Очистка настроек pigpio\npi.stop()\n\nЛистинг Б.2 — Обучение нейросети\nimport os\nos.chdir('MetaTree')\nimport sys\nsys.path.append('..')\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom metatree.model_metatree import LlamaForMetaTree as MetaTree\nfrom metatree.decision_tree_class import DecisionTree, DecisionTreeForest\nfrom metatree.run_train import preprocess_dimension_patch\nfrom transformers import AutoConfig\nfrom sklearn.metrics import accuracy_score\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport imodels\nimport random\nimport pandas as pd\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\nfrom scipy import signal, stats\nfrom sklearn.utils import resample\nfrom tqdm import tqdm\nimport pywt\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Загрузка данных\nfile_path = \"csv_bal/A1_new1.csv\"\ndf = pd.read_csv(file_path)\ndf['y'] = df['y'].replace({1: 0, 2: 1, 3: 2})  # Переименовываем классы\n# Разделяем признаки и целевую переменную\nX = df.drop(columns=['y'])\ny = df['y']\nX_balanced = X.values\ny_balanced = y.values\n# Split the data into training and testing sets\ntrain_X, test_X, train_y, test_y = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\nclass TabularDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = features\n        self.labels = labels\n    def __len__(self):\n        return len(self.features)\n    def __getitem__(self, idx):\n        feature = self.features[idx]\n        label = self.labels[idx]\n        return torch.tensor(feature, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n# Convert data to tensors\ntrain_features = train_X\ntrain_y_tensor = torch.tensor(train_y, dtype=torch.long)\ntrain_labels = torch.nn.functional.one_hot(train_y_tensor, num_classes=3).float().numpy()\n# Create Dataset\ntrain_dataset = TabularDataset(train_features, train_labels)\n# Parameters\nbatch_size = 64\nПродолжение Листинга Б.2\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    shuffle=True)\n# Initialize Model\nmodel_name_or_path = \"yzhuang/MetaTree\"\nconfig = AutoConfig.from_pretrained(model_name_or_path)\n# Override config parameters to match your dataset\nconfig.n_feature = train_X.shape[1]\nconfig.n_class = 3\nmodel = MetaTree.from_pretrained(\n    model_name_or_path,\n    config=config,\n    ignore_mismatched_sizes=True)\ndecision_tree_forest = DecisionTreeForest()\n# Set the depth of the model\nmodel.depth = 3\ntorch.cuda.empty_cache()\ntorch.cuda.empty_cache()\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu' \nprint(device)\nprint(next(model.parameters()).device)\nmodel = model.to(device)\nfrom tqdm import tqdm\nfrom torch.cuda.amp import autocast\n# Create a tqdm progress bar\nprogress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\nfor batch_idx, (batch_features, batch_labels) in progress_bar:\n    # Prepare the batch for the model\n    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n    batch = {\"input_x\": batch_features, \"input_y\": batch_labels, \"input_y_clean\": batch_labels}\n    batch = preprocess_dimension_patch(batch, n_feature=train_X.shape[1], n_class=3)\n    # Mixed precision training\n    with autocast():\n        # Generate decision tree\n        outputs = model.generate_decision_tree(batch['input_x'], batch['input_y'], depth=model.depth)     decision_tree_forest.add_tree(DecisionTree(auto_dims=outputs.metatree_dimensions, auto_thresholds=outputs.tentative_splits, input_x=batch['input_x'], input_y=batch['input_y'], depth=model.depth))      \n    # Update progress bar description\n    progress_bar.set_description(f\"Processing batch {batch_idx+1}/{len(train_loader)}\")\n        #print(\"Decision Tree Features: \", [x.argmax(dim=-1).item() for x in outputs.metatree_dimensions])\n    #print(\"Decision Tree Thresholds: \", outputs.tentative_splits)\ntorch.save(decision_tree_forest.state_dict(), 'model_weights.pth') \ntorch.save(decision_tree_forest, 'model_structure.pth')\n# Подготовка тестовых данных\ntest_X_tensor = torch.tensor(test_X, dtype=torch.float32).to(device)\nwith torch.no_grad():\n    tree_pred = decision_tree_forest.predict(test_X_tensor)\ntree_pred = tree_pred.argmax(dim=-1).squeeze().cpu().numpy()  # Переносим результат на CPU для последующей обработки\n# Calculate accuracy\naccuracy = accuracy_score(test_y, tree_pred)\nprint(\"MetaTree Test Accuracy: \", accuracy)\nMetaTree Test Accuracy:  0.7222222222222222\nЛистинг Б.3 — Файл convert.py\nimport os\nimport scipy.io\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef process_mat_files(input_dir='MotorImagery', output_dir='csv'):\n    # Создаем папку для результатов\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Ищем .mat файлы\n    mat_files = [f for f in os.listdir(input_dir) if f.endswith('.mat')]\n\n    print(f\"Найдено {len(mat_files)} .mat файлов для обработки:\")\n\n    for mat_file in tqdm(mat_files, desc=\"Обработка файлов\"):\n        try:\n            # Полный путь к файлу\n            mat_path = os.path.join(input_dir, mat_file)\n\n            # Загрузка .mat файла\n            mat_data = scipy.io.loadmat(mat_path)['o'][0, 0]\n\n            # Извлечение данных\n            channel_names = [name[0] for name in mat_data['chnames'][:, 0]]\n            data = mat_data['data']\n            markers = mat_data['marker']\n\n            # Создание DataFrame\n            df = pd.DataFrame(data, columns=channel_names)\n            df['y'] = markers\n\n            # Сохраняем в CSV\n            csv_name = os.path.splitext(mat_file)[0] + '.csv'\n            csv_path = os.path.join(output_dir, csv_name)\n\n            df.to_csv(csv_path, index=False, float_format='%.2f')\n            print(f\"\\nУспешно обработан: {mat_file} -> {csv_name}\")\n\n        except Exception as e:\n            print(f\"\\nОшибка при обработке {mat_file}: {str(e)}\")\n\n    print(\"\\nОбработка завершена.\")\n\n\n# Запускаем обработку\nprocess_mat_files()\n\nЛистинг Б.4 — Файл unite.py\nimport pandas as pd\nimport os\n\ndef merge_csv_files(input_directory, output_file):\n    # Получаем список всех CSV файлов в директории\n    csv_files = [f for f in os.listdir(input_directory) if f.endswith('.csv')]\n\n    # Читаем и объединяем все CSV файлы в один DataFrame\n    df_list = [pd.read_csv(os.path.join(input_directory, csv_file)) for csv_file in csv_files]\n    combined_df = pd.concat(df_list, ignore_index=True)\n\n    # Сохраняем объединенный DataFrame в новый CSV файл\n    combined_df.to_csv(output_file, index=False)\n\nmerge_csv_files('csv', 'test.csv')\n\nimport pandas as pd\n\n# Загрузите ваш CSV файл\nfile_path = 'MotorImagery/csv/CLASubjectB1510193StLRHand.csv'  # Замените на путь к вашему файлу\ndf = pd.read_csv(file_path)\n\n# Оставляем только необходимые столбцы\ncolumns_to_keep = ['F3', 'F4', 'C3', 'C4', 'P3', 'P4','O1','O2', 'y']\ndf = df[columns_to_keep]\n\n# Разделяем строки с y = 0 и строки с y != 0\ndf = df[df['y'] != 0]\ndf = df[df['y'] != 90]\ndf = df[df['y'] != 91]\ndf = df[df['y'] != 99]\ndf = df[df['y'] != 92]\ndf_LR = df[df['y'] != 3]\ndf_still = df[df['y'] == 3]\n\nif len(df_still) > len(df_LR):\n    # Подравниваем количество строк с y = 0 к количеству строк с y != 0\n    df_still = df_still.sample(n=int(len(df_LR)/2), random_state=42)  # Рандомный отбор строк\n    # Объединяем два подмножества обратно\n    balanced_df = pd.concat([df_LR, df_still])\n    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n    # Сохраняем результат в новый CSV файл\n    balanced_df.to_csv('MetaTree/B1_Test.csv', index=False)\nelse:\n    balanced_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n    balanced_df.to_csv('MetaTree/B1_Test.csv', index=False)\n\nprint(\"Датасет успешно отфильтрован и сохранен.\")\nprint(f\"Распределение классов:\\n{balanced_df['y'].value_counts()}\")\nЛистинг Б.5 — Файл preprocess.py\nimport pandas as pd\nimport numpy as np\nfrom scipy import signal, stats\nimport pywt\nfrom tqdm import tqdm\nfrom scipy.stats import entropy\nfrom scipy.signal import hilbert\n\ndef process_motor_eeg(input_file, output_file, window_size=250, overlap=0.5):\n    # Загрузка данных\n    df = pd.read_csv(input_file)\n    df['y'] = df['y'].replace({1: 0, 2: 1, 3: 2})\n    # Параметры\n    fs = 250  # Частота дискретизации\n    channels = ['F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2']\n    # 1. фильтрация\n    def apply_filters(data):\n        b, a = signal.butter(4, [8.0, 30.0], btype='bandpass', fs=fs)\n        filtered = signal.filtfilt(b, a, data)\n        coeffs = pywt.wavedec(filtered, 'db4', level=4)\n        return pywt.waverec(coeffs[:-2], 'db4')  # Удаление высокочастотных компонентов\n    processed_data = []\n    # 2. Обработка скользящим окном\n    for idx in tqdm(range(0, len(df) - window_size, int(window_size * (1 - overlap)))):\n        window = df.iloc[idx:idx + window_size]\n        features = {}\n        # 3. Извлечение ключевых признаков\n        for ch in ['C3', 'C4', 'F3', 'F4']:\n            signal_data = apply_filters(window[ch].values)\n            # Спектральные характеристики\n            f, Pxx = signal.welch(signal_data, fs=fs)\n            features.update({\n                f'{ch}_beta': Pxx[(f >= 13) & (f <= 30)].mean()\n            })\n            if (ch=='C3' or ch=='C4'):\n                features.update({\n                    f'{ch}_mu': Pxx[(f >= 8) & (f <= 12)].mean(),\n                    f'{ch}_std': np.std(signal_data)\n                })\n        # 4. Межканальные признаки\n        c3_beta = features['C3_beta']\n        c4_beta = features['C4_beta']\n        features.update({\n            'C3_C4_beta_ratio': c3_beta / (c4_beta + 1e-6),\n            'F3_F4_asymmetry': (features['F3_beta'] - features['F4_beta']) /\n                               (features['F3_beta'] + features['F4_beta'] + 1e-6),\n            'motor_cortex_diff': np.abs(c3_beta - c4_beta),\n            'C3_C4_crosscorr': np.correlate(window['C3'].values, window['C4'].values)[0]\n        })\n        # Теменные и затылочные признаки\n        for ch in ['P3', 'P4', 'O1', 'O2']:\n            signal_data = apply_filters(window[ch].values)\n            f, Pxx = signal.welch(signal_data, fs=fs)\n            # Ключевые особенности для задних областей\n            features.update({\n                f'{ch}_alpha': Pxx[(f >= 8) & (f <= 12)].mean(),\n                f'{ch}_gamma': Pxx[(f > 30) & (f <= 45)].mean(),\nПродолжение Листинга Б.5\n              f'{ch}_hjorth_mobility': np.std(np.diff(signal_data)) / np.std(signal_data)\n            })\n        # Межканальные отношения\n        features.update({\n            'P3_P4_alpha_diff': features['P3_alpha'] - features['P4_alpha'],\n            'Occipital_gamma_mean': np.mean([features['O1_gamma'], features['O2_gamma']])\n        })\n        # 5. Определение метки класса\n        try:\n            features['y'] = stats.mode(window['y'], keepdims=True)[0][0]\n        except:\n            features['y'] = window['y'].iloc[0]\n        processed_data.append(features)\n    # 6. Создание нового датафрейма\n    processed_df = pd.DataFrame(processed_data)\n    key_features = [\n        # Моторные\n        'C3_beta', 'C4_beta', 'C3_mu',\n        'F3_beta', 'F4_beta',\n        # Фронтальные\n        'F3_F4_asymmetry',\n        'motor_cortex_diff',\n        # Новые признаки\n        'C3_C4_crosscorr',\n        # Теменные\n        'P3_P4_alpha_diff',\n        # Затылочные\n        'Occipital_gamma_mean',\n        # Общие\n        'y'    ]\n    processed_df = processed_df[key_features]\n    # 7. Балансировка классов\n    min_class = processed_df['y'].value_counts().min()\n    balanced_df = processed_df.groupby('y').apply(\n        lambda x: x.sample(min_class, random_state=42)\n    ).reset_index(drop=True)\n    # 8. Сохранение в CSV\n    balanced_df.to_csv(output_file, index=False)\n    print(f\"Обработанные данные сохранены в: {output_file}\")\n    return balanced_df\n\nif __name__ == \"__main__\":\n    process_motor_eeg(\n        input_file=\"MetaTree/csv_bal/A1.csv\",\n        output_file=\"MetaTree/csv_bal/A1_new1.csv\"\n    )", "entities": [[1187, 1197, "PERSON"], [1269, 1305, "PERSON"], [1434, 1468, "PERSON"], [1691, 1719, "PERSON"], [4547, 4557, "PERSON"], [5273, 5322, "ADDRESS"], [5380, 5406, "PERSON"], [5578, 5598, "PERSON"], [12291, 12366, "ADDRESS"], [22333, 22353, "PERSON"], [23071, 23076, "PERSON"], [23117, 23131, "PERSON"], [24975, 24985, "PERSON"], [25295, 25306, "PERSON"], [26285, 26296, "PERSON"], [27393, 27403, "PERSON"], [29541, 29546, "PERSON"], [30877, 30899, "PERSON"], [31602, 31612, "PERSON"], [31693, 31697, "PERSON"], [31699, 31703, "PERSON"], [33472, 33481, "PERSON"], [33902, 33912, "PERSON"], [34426, 34434, "PERSON"], [36369, 36379, "PERSON"], [36476, 36494, "PERSON"], [39644, 39659, "PERSON"], [40868, 40878, "PERSON"], [41143, 41153, "PERSON"], [43643, 43666, "PERSON"], [44417, 44428, "ADDRESS"], [44598, 44625, "PERSON"], [44633, 44667, "PERSON"], [48248, 48258, "PERSON"], [48413, 48426, "PERSON"], [49462, 49480, "PERSON"], [49956, 49968, "PERSON"], [50138, 50153, "PERSON"], [50289, 50302, "PERSON"], [50846, 50923, "ADDRESS"], [50956, 50975, "PERSON"], [51055, 51066, "ADDRESS"], [51068, 51078, "PERSON"], [51727, 51770, "ADDRESS"], [52189, 52208, "PERSON"], [52796, 52805, "PERSON"], [52912, 52927, "PERSON"], [53085, 53136, "ADDRESS"], [53774, 53784, "PERSON"], [56084, 56278, "ADDRESS"], [56466, 56492, "PERSON"], [56784, 56820, "PERSON"], [57868, 57880, "PERSON"], [57882, 57893, "PERSON"], [58660, 58673, "PERSON"], [61831, 61847, "PERSON"], [61993, 62013, "PERSON"], [62735, 62757, "PERSON"], [62900, 62926, "PERSON"], [63095, 63115, "PERSON"], [63405, 63427, "PERSON"], [63460, 63482, "PERSON"], [63526, 63536, "PERSON"], [63555, 63568, "PERSON"], [63625, 63635, "PERSON"], [63639, 63662, "PERSON"], [63776, 63786, "PERSON"], [63804, 63817, "PERSON"], [63979, 63989, "PERSON"], [64013, 64026, "PERSON"], [64105, 64115, "PERSON"], [64139, 64152, "PERSON"], [64323, 64388, "ADDRESS"], [64391, 64401, "PERSON"], [64427, 64440, "PERSON"], [64546, 64556, "PERSON"], [64580, 64593, "PERSON"], [64701, 64706, "PERSON"], [64789, 64799, "PERSON"], [64803, 64823, "PERSON"], [64824, 64837, "PERSON"], [64943, 64953, "PERSON"], [64975, 64988, "PERSON"], [65169, 65179, "PERSON"], [65184, 65207, "PERSON"], [65307, 65317, "PERSON"], [65353, 65366, "PERSON"], [65458, 65468, "PERSON"], [65473, 65494, "PERSON"], [65641, 65651, "PERSON"], [65656, 65677, "PERSON"], [65713, 65723, "PERSON"], [65770, 65780, "PERSON"], [65784, 65799, "PERSON"], [67855, 67878, "PERSON"], [70671, 70694, "PERSON"], [71862, 71867, "PERSON"], [73086, 73109, "PERSON"], [74675, 74685, "PERSON"], [76720, 76743, "PERSON"], [79237, 79247, "PERSON"], [80703, 80713, "PERSON"], [81318, 81331, "PERSON"], [82550, 82560, "PERSON"], [85075, 85098, "PERSON"]]}
